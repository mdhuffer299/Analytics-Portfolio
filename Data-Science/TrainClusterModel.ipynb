{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Cluster Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all required modules including Oracle Connection and Data Processing Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:21.249143Z",
     "start_time": "2019-12-20T18:23:15.308009Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import os \n",
    "import cx_Oracle\n",
    "import statsmodels.api as sm\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Update path to where function file resides\n",
    "if os.name == 'nt':\n",
    "    state = !cd\n",
    "    \n",
    "    # Load DB Connection File from Windows Machine\n",
    "    os.chdir(r'Directory name')\n",
    "    from db_connection import oracle_connection\n",
    "    \n",
    "    # Load function file from Windows Machine\n",
    "    os.chdir(r'directory name')\n",
    "    from general_functions import *\n",
    "elif os.name == 'posix':\n",
    "    state = !pwd\n",
    "    \n",
    "    # Load DB Connection File from Mac Machine\n",
    "    os.chdir('directory name')\n",
    "    from db_connection import oracle_connection\n",
    "    \n",
    "    # Load function file from Mac Machine\n",
    "    os.chdir('directory name')\n",
    "    from general_functions import *\n",
    "else:\n",
    "    print('No OS!')\n",
    "\n",
    "#Change directory back to working Jupyter Notebook Directory after importing connection module\n",
    "os.chdir(state[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DB Connection String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:23.681762Z",
     "start_time": "2019-12-20T18:23:21.257167Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    # Update path to where config file resides\n",
    "    db_creds = os.path.expanduser('~') + 'directory name'\n",
    "    creds = oracle_connection(db_creds)\n",
    "\n",
    "    url = creds['host'] + \":\" + creds['port'] + \"/\" + creds['database']\n",
    "\n",
    "    db = cx_Oracle.connect(creds['user'], creds['password'], url)\n",
    "\n",
    "    cursor = db.cursor()\n",
    "elif os.name == 'posix':\n",
    "    # Update path to where config file resides\n",
    "    db_creds = os.path.expanduser('~') + 'directory name'\n",
    "    creds = oracle_connection(db_creds)\n",
    "\n",
    "    url = creds['host'] + \":\" + creds['port'] + \"/\" + creds['database']\n",
    "\n",
    "    db = cx_Oracle.connect(creds['user'], creds['password'], url, encoding = 'UTF-8')\n",
    "    cursor = db.cursor()\n",
    "else:\n",
    "    print('No OS!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send query to Oracle database and return as Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:24.924460Z",
     "start_time": "2019-12-20T18:23:23.690786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update schema to your schema\n",
    "query = \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "df = pd.read_sql(query, cursor.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:24.972289Z",
     "start_time": "2019-12-20T18:23:24.928717Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:25.013360Z",
     "start_time": "2019-12-20T18:23:24.977841Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tr = df.copy()\n",
    "df_tr = df_tr.drop([\"column\"], axis = 1)\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:25.164952Z",
     "start_time": "2019-12-20T18:23:25.017469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Dictionary that contains the column names as key and the corresponsing value to fill missing value in column as value\n",
    "dtype_dict_value = replace_values(df_tr, char_value = 'Unknown')\n",
    "df_tr.fillna(value = dtype_dict_value, inplace = True)\n",
    "\n",
    "# Convert the categories into a cateogry level (aka Encode the Category value)\n",
    "# Return covnerted DF and the dictionary that contains the key-value pair for columns category code mappings.\n",
    "df_tr, forward_mapping_dict, inv_mapping_dict, encoder_fit = convert_cat_to_cat_lvl(df_tr, encode_method = 'Numeric')\n",
    "\n",
    "df_tr[df_tr.isnull().any(axis = 1)]\n",
    "\n",
    "%store forward_mapping_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and Test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:25.187763Z",
     "start_time": "2019-12-20T18:23:25.170120Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_tr, test_size = 0.3, random_state = 5)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the K-Means based on the number of clusters and cost associated with each respective cluster.\n",
    "#### Look for inflection point in graph or cost between clusters in minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:26.770693Z",
     "start_time": "2019-12-20T18:23:25.192719Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cluster the data (determine the optimal cluster based on cost)\n",
    "k_list_full = []\n",
    "cost_list_full = []\n",
    "\n",
    "for k in range(1,16):\n",
    "        \n",
    "    kmeans_full = KMeans(n_clusters=k, random_state=0).fit(train_df)\n",
    "    labels = kmeans_full.labels_\n",
    "    inertia = kmeans_full.inertia_\n",
    "\n",
    "    k_list_full.append(k)\n",
    "    cost_list_full.append(inertia)\n",
    "    \n",
    "    print(\"K: \", k, \"Cost: \", inertia)\n",
    "    \n",
    "k_df_full = pd.DataFrame(list(zip(k_list_full, cost_list_full)), columns = ['k', 'cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.227014Z",
     "start_time": "2019-12-20T18:23:26.774780Z"
    }
   },
   "outputs": [],
   "source": [
    "k_df_full.plot(x = 'k', y = 'cost', figsize = (18, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train K-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.337826Z",
     "start_time": "2019-12-20T18:23:27.231085Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_full = KMeans(n_clusters = 6, random_state = 0).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.374059Z",
     "start_time": "2019-12-20T18:23:27.340964Z"
    }
   },
   "outputs": [],
   "source": [
    "train_app_df = train_df.copy()\n",
    "train_app_df['CLUSTER'] = kmeans_full.labels_\n",
    "train_app_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.495224Z",
     "start_time": "2019-12-20T18:23:27.437218Z"
    }
   },
   "outputs": [],
   "source": [
    "test_app_df = test_df.copy()\n",
    "test_app_df['CLUSTER'] = kmeans_full.predict(test_df)\n",
    "test_app_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.518043Z",
     "start_time": "2019-12-20T18:23:27.498670Z"
    }
   },
   "outputs": [],
   "source": [
    "test_app_df['CLUSTER'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform PCA to reduce the dimensionality of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.549590Z",
     "start_time": "2019-12-20T18:23:27.522711Z"
    }
   },
   "outputs": [],
   "source": [
    "df_std = df_tr.copy()\n",
    "\n",
    "scaler_fit = StandardScaler().fit(df_std)\n",
    "df_std = pd.DataFrame(scaler_fit.transform(df_std), columns = df_std.columns)\n",
    "\n",
    "df_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.590828Z",
     "start_time": "2019-12-20T18:23:27.556265Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_fit = pca.fit(df_std)\n",
    "principalComponents = pca_fit.transform(df_std)\n",
    "pca_df = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PCA_1', 'PCA_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and Test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:27.606506Z",
     "start_time": "2019-12-20T18:23:27.593931Z"
    }
   },
   "outputs": [],
   "source": [
    "train_pca_df, test_pca_df = train_test_split(pca_df, test_size = 0.3, random_state = 5)\n",
    "print(train_pca_df.shape, test_pca_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the K-Means based on the number of clusters and cost associated with each respective cluster.\n",
    "#### Look for inflection point in graph or cost between clusters in minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:29.147372Z",
     "start_time": "2019-12-20T18:23:27.610350Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cluster the data (determine the optimal cluster based on cost) for the PCA reduced dataset\n",
    "k_list_pca = []\n",
    "cost_list_pca = []\n",
    "\n",
    "for k in range(1,16):\n",
    "        \n",
    "    kmeans_pca = KMeans(n_clusters=k, random_state=0).fit(train_pca_df)\n",
    "    labels = kmeans_pca.labels_\n",
    "    inertia = kmeans_pca.inertia_\n",
    "\n",
    "    k_list_pca.append(k)\n",
    "    cost_list_pca.append(inertia)\n",
    "    \n",
    "    print(\"K: \", k, \"Cost: \", inertia)\n",
    "    \n",
    "k_df_pca = pd.DataFrame(list(zip(k_list_pca, cost_list_pca)), columns = ['k', 'cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:29.594805Z",
     "start_time": "2019-12-20T18:23:29.156705Z"
    }
   },
   "outputs": [],
   "source": [
    "k_df_pca.plot(x = 'k', y = 'cost', figsize = (18, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:29.708474Z",
     "start_time": "2019-12-20T18:23:29.598986Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_pca = KMeans(n_clusters = 6, random_state = 0).fit(train_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:29.737591Z",
     "start_time": "2019-12-20T18:23:29.715030Z"
    }
   },
   "outputs": [],
   "source": [
    "train_app_pca_df = train_pca_df.copy()\n",
    "train_app_pca_df['CLUSTER'] = kmeans_pca.labels_\n",
    "train_app_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:29.779998Z",
     "start_time": "2019-12-20T18:23:29.741361Z"
    }
   },
   "outputs": [],
   "source": [
    "test_app_pca_df = test_pca_df.copy()\n",
    "test_app_pca_df['CLUSTER'] = kmeans_pca.predict(test_pca_df)\n",
    "test_app_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:29.826507Z",
     "start_time": "2019-12-20T18:23:29.789098Z"
    }
   },
   "outputs": [],
   "source": [
    "test_app_pca_df['CLUSTER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:30.621789Z",
     "start_time": "2019-12-20T18:23:29.834594Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = test_app_pca_df.plot(x = 'PCA_1', y = 'PCA_2', kind = 'scatter', c = 'CLUSTER', colormap = 'cool', figsize = (18, 16))\n",
    "ax.set_facecolor = (\"grey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize the model to disk for future use and version control.\n",
    "#### Update version if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:30.697074Z",
     "start_time": "2019-12-20T18:23:30.628977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "joblib.dump(kmeans_full, './Model/kmeans_dlm_full_v2.0.pkl')\n",
    "joblib.dump(kmeans_pca, './Model/kmeans_dlm_pca_v2.0.pkl')\n",
    "\n",
    "# Transformations\n",
    "joblib.dump(scaler_fit, './Model/kmeans_dlm_scaler_v2.0.pkl')\n",
    "joblib.dump(pca_fit, './Model/kmeans_dlm_pca_fit_v2.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
