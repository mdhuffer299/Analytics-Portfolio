{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Cluster Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:42.952426Z",
     "start_time": "2019-12-20T18:23:36.328798Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import os \n",
    "import cx_Oracle\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Update path to where function file resides\n",
    "if os.name == 'nt':\n",
    "    state = !cd\n",
    "    \n",
    "    # Load DB Connection File from Windows Machine\n",
    "    os.chdir(r'Directory Name')\n",
    "    from db_connection import oracle_connection\n",
    "    \n",
    "    # Load function file from Windows Machine\n",
    "    os.chdir(r'Directory Name')\n",
    "    from general_functions import *\n",
    "elif os.name == 'posix':\n",
    "    state = !pwd\n",
    "    \n",
    "    # Load DB Connection File from Mac Machine\n",
    "    os.chdir('Directory Name')\n",
    "    from db_connection import oracle_connection\n",
    "    \n",
    "    # Load function file from Mac Machine\n",
    "    os.chdir('Directory Name')\n",
    "    from general_functions import *\n",
    "else:\n",
    "    print('No OS!')\n",
    "\n",
    "#Change directory back to working Jupyter Notebook Directory after importing connection module\n",
    "os.chdir(state[0])\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DB Connection String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:23:45.183437Z",
     "start_time": "2019-12-20T18:23:42.996742Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    # Update path to where config file resides\n",
    "    db_creds = os.path.expanduser('~') + 'Directory Name'\n",
    "    creds = oracle_connection(db_creds)\n",
    "\n",
    "    url = creds['host'] + \":\" + creds['port'] + \"/\" + creds['database']\n",
    "\n",
    "    db = cx_Oracle.connect(creds['user'], creds['password'], url)\n",
    "\n",
    "    cursor = db.cursor()\n",
    "elif os.name == 'posix':\n",
    "    # Update path to where config file resides\n",
    "    db_creds = os.path.expanduser('~') + 'Directory Name'\n",
    "    creds = oracle_connection(db_creds)\n",
    "\n",
    "    url = creds['host'] + \":\" + creds['port'] + \"/\" + creds['database']\n",
    "\n",
    "    db = cx_Oracle.connect(creds['user'], creds['password'], url, encoding = 'UTF-8')\n",
    "    cursor = db.cursor()\n",
    "else:\n",
    "    print('No OS!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send query to Oracle database and return as Pandas DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:00.311302Z",
     "start_time": "2019-12-20T18:23:45.188923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data for clustering process\n",
    "query = \"\"\"\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "df = pd.read_sql(query, cursor.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:00.528370Z",
     "start_time": "2019-12-20T18:27:00.315274Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tr = df.copy()\n",
    "df_tr = df_tr.drop([\"ACCT_ID\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:00.919493Z",
     "start_time": "2019-12-20T18:27:00.531491Z"
    }
   },
   "outputs": [],
   "source": [
    "dtype_dict_value = replace_values(df_tr, 'Unknown')\n",
    "df_tr.fillna(value = dtype_dict_value, inplace = True)\n",
    "\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:01.974641Z",
     "start_time": "2019-12-20T18:27:00.922170Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tr, forward_mapping_dict, inv_mapping_dict, encoder_fit = convert_cat_to_cat_lvl(df_tr, encode_method = 'Numeric')\n",
    "\n",
    "df_tr[df_tr.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Serialized K-Means Cluster models from disk and score new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:01.994139Z",
     "start_time": "2019-12-20T18:27:01.977505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "kmeans_dlm_full = joblib.load('./Model/kmeans_dlm_full_v2.0.pkl')\n",
    "kmeans_dlm_pca = joblib.load('./Model/kmeans_dlm_pca_v2.0.pkl')\n",
    "\n",
    "# Transformations\n",
    "scaler_fit = joblib.load('./Model/kmeans_dlm_scaler_v2.0.pkl')\n",
    "pca_fit = joblib.load('./Model/kmeans_dlm_pca_fit_v2.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:02.513951Z",
     "start_time": "2019-12-20T18:27:01.997674Z"
    }
   },
   "outputs": [],
   "source": [
    "df_std = df_tr.copy()\n",
    "\n",
    "df_std = StandardScaler().fit_transform(df_std)\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "principalComponents = pca_fit.fit_transform(df_std)\n",
    "pca_df = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PCA_1', 'PCA_2'])\n",
    "\n",
    "\n",
    "df_tr['FULL_CLUSTER'] = kmeans_dlm_full.predict(df_tr)\n",
    "df_tr['PCA_CLUSTER'] = kmeans_dlm_pca.predict(pca_df)\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the columns that were converted to category levels back to category values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:02.764686Z",
     "start_time": "2019-12-20T18:27:02.517173Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, val in enumerate(inv_mapping_dict.keys()):\n",
    "    col = list(inv_mapping_dict.keys())[idx]\n",
    "    mapping = list(inv_mapping_dict.values())[idx]\n",
    "    col_name = col.replace(\"_CAT\", \"\")\n",
    "    df_tr[col_name] = df_tr[col].map(mapping)\n",
    "\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:27:03.689854Z",
     "start_time": "2019-12-20T18:27:02.771530Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = df.join(df_tr[['COLUMN NAMES']], lsuffix = '_ORIG', rsuffix = '_TEST')\n",
    "final_df.drop(final_df.columns.difference(['COLUMN NAMES']), axis = 1, inplace = True)\n",
    "final_df.rename(columns = {'COLUMN NAMES'}, inplace = True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data back to Oracle Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:28:37.344833Z",
     "start_time": "2019-12-20T18:28:37.088801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop target table\n",
    "\n",
    "drop_table_sql = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(drop_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:28:37.485023Z",
     "start_time": "2019-12-20T18:28:37.353793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create target table\n",
    "create_table_sql = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T18:28:47.572899Z",
     "start_time": "2019-12-20T18:28:37.874537Z"
    }
   },
   "outputs": [],
   "source": [
    "# insert into target table\n",
    "\n",
    "records = [tuple(x) for x in final_df.values]\n",
    "cursor.executemany('''''', records)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
